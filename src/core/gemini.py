"""
Module contains all functions related to interacting with Google Gemini
"""

# pylint: disable = wrong-import-position
# pylint: disable = wrong-import-order

import os
import sys
import dotenv

sys.path.append(os.getcwd())
dotenv.load_dotenv()

import json

import httpx

from src.models.models_gemini import (
    ChatMessage,
    ChatMessagePart,
    GeminiRoles,
    ChatHistory,
)


def get_response_from_gemini(messages: ChatHistory) -> str | None:
    """
    Sends the chat history to Gemini and returns the response.

    Args:
        messages (ChatHistory): The chat history containing the conversation messages.

    Returns:
        str | None: The response generated by Gemini, or None if an error occurred.

    """

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro:generateContent?key={os.getenv('GOOGLE_GEMINI_KEY')}"
    payload = {
        "generationConfig": {
            "temperature": 0.9,
            "topK": 1,
            "topP": 1,
            "maxOutputTokens": 2048,
            "stopSequences": [],
        },
        "safetySettings": [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_ONLY_HIGH"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_ONLY_HIGH"},
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_ONLY_HIGH",
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_ONLY_HIGH",
            },
        ],
    }

    payload.update(messages.model_dump())
    print(messages.model_dump())

    response = httpx.post(url, data=json.dumps(payload, default=str), timeout=120)

    try:
        reply = (
            response.json()
            .get("candidates")[0]
            .get("content")
            .get("parts")[0]
            .get("text")
        )

        print(reply)
        return reply

    except Exception:
        print(f"Unable to extract message from AI: {response.text}")
        return None


def construct_chat_history(messages: list[dict[str, str]]) -> ChatHistory:
    """
    Constructs a chat history in Gemini format.

    Args:
        messages (list[dict]): A list of messages containing information about each message.

    Returns:
        ChatHistory: The constructed chat history in Gemini format.
    """

    chat_history = []

    for message in messages:
        if message["role"] == "user":
            message_text = ChatMessagePart(text=message["text"])
            chat_message = ChatMessage(role=GeminiRoles.USER, parts=[message_text])
            chat_history.append(chat_message)
        else:
            message_text = ChatMessagePart(text=message["text"])
            chat_message = ChatMessage(role=GeminiRoles.AI, parts=[message_text])
            chat_history.append(chat_message)

    validated_chat_history = ChatHistory(contents=chat_history)

    return validated_chat_history


if __name__ == "__main__":
    constructed_msg_history = construct_chat_history(
        [
            {"role": "user", "text": "Hello"},
            {"role": "model", "text": "Hello! How can I assist you today?"},
            {"role": "user", "text": "What is 1+1?"},
        ]
    )

    get_response_from_gemini(constructed_msg_history)
